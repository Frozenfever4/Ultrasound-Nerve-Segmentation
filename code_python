#necessary imports and configuration

import os, time, random
from glob import glob
import numpy as np
import cv2
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split

%matplotlib inline

class CFG:
    IMG_SIZE = 256
    BATCH = 8
    LR = 1e-4
    EPOCHS = 50
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# Dataset and Visualization

class KaggleNerveDataset(Dataset):
    def __init__(self, image_folder):
        self.image_paths = sorted([os.path.join(image_folder,f) 
                                   for f in os.listdir(image_folder) if "_mask" not in f])
        self.mask_paths = [f.replace(".tif","_mask.tif") for f in self.image_paths]

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img = cv2.imread(self.image_paths[idx],0)
        mask = cv2.imread(self.mask_paths[idx],0)

        img = cv2.resize(img,(CFG.IMG_SIZE,CFG.IMG_SIZE))/255.0
        mask = cv2.resize(mask,(CFG.IMG_SIZE,CFG.IMG_SIZE))
        mask = (mask>127).astype(np.float32)

        return (
            torch.tensor(img).unsqueeze(0).float(),
            torch.tensor(mask).unsqueeze(0).float()
        )


def visualize_input(img, mask):
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1); plt.imshow(img.squeeze(), cmap='gray'); plt.title("Raw Image")
    plt.subplot(1,2,2); plt.imshow(mask.squeeze(), cmap='viridis'); plt.title("GT Mask")
    plt.axis('off'); plt.show()


train_path = "/kaggle/input/ultrasound-nerve-segmentation/train/"
nerve_data = KaggleNerveDataset(train_path)

sample_img, sample_mask = nerve_data[0]
visualize_input(sample_img, sample_mask)


# Diffusion Denoiser

class DiffusionDenoiser(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(1,32,3,padding=1), nn.ReLU(),
            nn.Conv2d(32,32,3,padding=1), nn.ReLU(),
            nn.Conv2d(32,1,3,padding=1)
        )

    def forward(self,x):
        noise = self.net(x)
        return torch.clamp(x-noise,0,1)


def visualize_denoising(raw, denoised):
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1); plt.imshow(raw.squeeze(), cmap='gray'); plt.title("Raw")
    plt.subplot(1,2,2); plt.imshow(denoised.squeeze(), cmap='gray'); plt.title("Denoised")
    plt.axis('off'); plt.show()


denoiser = DiffusionDenoiser().eval()
with torch.no_grad():
    den = denoiser(sample_img.unsqueeze(0))
visualize_denoising(sample_img, den[0])


# Edge Extraction

class EdgeExtractor(nn.Module):
    def __init__(self):
        super().__init__()
        kx = torch.tensor([[-1,0,1],[-2,0,2],[-1,0,1]]).float().view(1,1,3,3)
        ky = torch.tensor([[-1,-2,-1],[0,0,0],[1,2,1]]).float().view(1,1,3,3)
        self.register_buffer('kx',kx)
        self.register_buffer('ky',ky)

    def forward(self,x):
        gx = F.conv2d(x,self.kx,padding=1)
        gy = F.conv2d(x,self.ky,padding=1)
        return torch.sqrt(gx**2+gy**2+1e-6)


edge_ext = EdgeExtractor().eval()
with torch.no_grad():
    edges = edge_ext(den)


plt.imshow(edges[0].squeeze(), cmap='magma')
plt.title("Edge Map")
plt.colorbar(); plt.show()


# Edge-Fusion UNet

class ConvBlock(nn.Module):
    def __init__(self,in_c,out_c):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_c,out_c,3,padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(),
            nn.Conv2d(out_c,out_c,3,padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU()
        )
    def forward(self,x): return self.net(x)

class EdgeFusionUNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.denoiser = DiffusionDenoiser()
        self.edge = EdgeExtractor()

        self.enc1 = ConvBlock(3,32)
        self.enc2 = ConvBlock(32,64)
        self.bott = ConvBlock(64,128)

        self.dec2 = ConvBlock(128+64,64)
        self.dec1 = ConvBlock(64+32,32)

        self.out = nn.Conv2d(32,1,1)

    def forward(self,x):
        xd = self.denoiser(x)
        xe = self.edge(xd)
        fused = torch.cat([x,xd,xe],1)

        c1 = self.enc1(fused); p1 = F.max_pool2d(c1,2)
        c2 = self.enc2(p1); p2 = F.max_pool2d(c2,2)
        b  = self.bott(p2)

        u2 = F.interpolate(b,scale_factor=2)
        u2 = self.dec2(torch.cat([u2,c2],1))
        u1 = F.interpolate(u2,scale_factor=2)
        u1 = self.dec1(torch.cat([u1,c1],1))

        return torch.sigmoid(self.out(u1)), xd, xe


model = EdgeFusionUNet().eval()
with torch.no_grad():
    pred, xd, xe = model(sample_img.unsqueeze(0))


def visualize_full(raw, den, edge, pred, gt):
    titles = ["Raw","Denoised","Edges","Prediction","GT"]
    imgs = [raw, den, edge, pred, gt]

    plt.figure(figsize=(22,4))
    for i in range(5):
        plt.subplot(1,5,i+1)
        plt.imshow(imgs[i].squeeze(), cmap='gray')
        plt.title(titles[i]); plt.axis('off')
    plt.show()


visualize_full(sample_img, xd[0], xe[0], pred[0], sample_mask)


# Loaders

def build_loaders():
    imgs = sorted([f for f in glob(train_path+"*.tif") if "_mask" not in f])
    masks = sorted([f for f in glob(train_path+"*.tif") if "_mask" in f])

    tr_i, val_i, tr_m, val_m = train_test_split(
        imgs, masks, test_size=0.2, random_state=42)

    train_ds = KaggleNerveDataset(train_path)
    val_ds   = KaggleNerveDataset(train_path)

    return (
        DataLoader(train_ds,CFG.BATCH,shuffle=True),
        DataLoader(val_ds,CFG.BATCH,shuffle=False)
    )


# Metrics

def metrics(pred, gt):
    pred = (pred>0.5).float()
    tp = (pred*gt).sum()
    fp = (pred*(1-gt)).sum()
    fn = ((1-pred)*gt).sum()

    dice = (2*tp)/(2*tp+fp+fn+1e-6)
    precision = tp/(tp+fp+1e-6)
    recall = tp/(tp+fn+1e-6)
    accuracy = (pred==gt).float().mean()

    return dice.item(), precision.item(), recall.item(), accuracy.item()


# Training Loop

def train(model, loader):
    model.to(CFG.device)
    opt = torch.optim.Adam(model.parameters(),CFG.LR)
    loss_fn = nn.BCELoss()

    hist = {"loss":[], "dice":[], "prec":[], "rec":[], "acc":[]}

    for ep in range(CFG.EPOCHS):
        model.train()
        for x,y in loader:
            x,y = x.to(CFG.device), y.to(CFG.device)
            p,_,_ = model(x)
            loss = loss_fn(p,y)

            opt.zero_grad(); loss.backward(); opt.step()

        model.eval()
        d=p=r=a=0
        with torch.no_grad():
            for x,y in loader:
                x,y = x.to(CFG.device), y.to(CFG.device)
                p,_,_ = model(x)
                md,mp,mr,ma = metrics(p,y)
                d+=md; p+=mp; r+=mr; a+=ma

        hist["loss"].append(loss.item())
        hist["dice"].append(d/len(loader))
        hist["prec"].append(p/len(loader))
        hist["rec"].append(r/len(loader))
        hist["acc"].append(a/len(loader))

        print(f"Epoch {ep+1} Dice {hist['dice'][-1]:.4f}")

    return hist


train_loader,_ = build_loaders()
edgefusion = EdgeFusionUNet()
history = train(edgefusion, train_loader)



# history should be like this
#history = {
#    "train_loss": [],
#    "val_loss": [],
#    "train_dice": [],
#    "val_dice": [],
#    "train_acc": [],
#    "val_acc": [],
#    "train_prec": [],
#    "val_prec": [],
#    "train_rec": [],
#    "val_rec": [],
#    "epoch_time": []   # seconds per epoch
#}


# Plots

plt.plot(history["dice"]); plt.title("Dice"); plt.grid(); plt.show()
plt.plot(history["prec"],label="Precision")
plt.plot(history["rec"],label="Recall")
plt.legend(); plt.grid(); plt.show()
plt.plot(history["acc"]); plt.title("Accuracy"); plt.grid(); plt.show()


plt.figure(figsize=(6,4))
plt.plot(history["train_loss"], label="Train Loss")
plt.plot(history["val_loss"], label="Val Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()
plt.grid()
plt.show()


plt.figure(figsize=(6,4))
plt.plot(history["train_dice"], label="Train Dice")
plt.plot(history["val_dice"], label="Val Dice")
plt.xlabel("Epoch")
plt.ylabel("Dice Score")
plt.title("Training vs Validation Dice")
plt.legend()
plt.grid()
plt.show()


plt.figure(figsize=(6,4))
plt.plot(history["train_prec"], label="Train Precision")
plt.plot(history["val_prec"], label="Val Precision")
plt.plot(history["train_rec"], label="Train Recall")
plt.plot(history["val_rec"], label="Val Recall")
plt.xlabel("Epoch")
plt.ylabel("Score")
plt.title("Precision & Recall Curves")
plt.legend()
plt.grid()
plt.show()


plt.figure(figsize=(6,4))
plt.plot(history["train_acc"], label="Train Accuracy")
plt.plot(history["val_acc"], label="Val Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Training vs Validation Accuracy")
plt.legend()
plt.grid()
plt.show()


all_probs = []
all_gt = []

from sklearn.metrics import roc_curve, auc

fpr, tpr, _ = roc_curve(all_gt, all_probs)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(5,5))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.4f}")
plt.plot([0,1],[0,1],'--')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve (EdgeFusionNet)")
plt.legend()
plt.grid()
plt.show()


plt.figure(figsize=(6,4))
plt.plot(history["epoch_time"])
plt.xlabel("Epoch")
plt.ylabel("Time (seconds)")
plt.title("Computational Time per Epoch")
plt.grid()
plt.show()

print("Avg Epoch Time:", np.mean(history["epoch_time"]))


plt.figure(figsize=(6,4))
plt.plot(history["val_loss"], label="Val Loss")
plt.plot(history["val_dice"], label="Val Dice")
plt.xlabel("Epoch")
plt.title("Loss vs Dice Progression")
plt.legend()
plt.grid()
plt.show()


gap = np.array(history["train_dice"]) - np.array(history["val_dice"])

plt.figure(figsize=(6,4))
plt.plot(gap)
plt.xlabel("Epoch")
plt.ylabel("Dice Gap (Train âˆ’ Val)")
plt.title("Overfitting Analysis")
plt.grid()
plt.show()

