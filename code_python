import os, time, random
from glob import glob
import numpy as np
import cv2
import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split

# ------------------------
# Config
# ------------------------
class CFG:
    IMG_SIZE = 256
    BATCH = 8 
    LR = 1e-4
    EPOCHS = 10
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    SAVE_DIR = "/kaggle/working/models"

os.makedirs(CFG.SAVE_DIR, exist_ok=True)

# ------------------------
# Dataset
# ------------------------
class UltrasoundDataset(Dataset):
    def __init__(self, img_paths, mask_paths):
        self.imgs = img_paths
        self.masks = mask_paths

    def __len__(self): 
        return len(self.imgs)

    def __getitem__(self, idx):
        img = cv2.imread(self.imgs[idx], 0)
        img = cv2.resize(img, (CFG.IMG_SIZE, CFG.IMG_SIZE))
        img = img.astype(np.float32) / 255.0

        mask = cv2.imread(self.masks[idx], 0)
        mask = cv2.resize(mask, (CFG.IMG_SIZE, CFG.IMG_SIZE))
        mask = (mask > 127).astype(np.float32)

        img = torch.tensor(img).unsqueeze(0)
        mask = torch.tensor(mask).unsqueeze(0)
        return img, mask

# ------------------------
# Kaggle-safe Loader
# ------------------------
def build_loaders():
    base = "/kaggle/input/ultrasound-nerve-segmentation"
    if os.path.exists(base + "/ultrasound-nerve-segmentation"):
        base = base + "/ultrasound-nerve-segmentation"

    train_path = base + "/train/"
    test_path  = base + "/test/"

    all_train = sorted(glob(train_path + "*.tif"))
    train_imgs  = [f for f in all_train if "_mask" not in f]
    train_masks = [f for f in all_train if "_mask" in f]

    all_test = sorted(glob(test_path + "*.tif"))
    test_imgs  = [f for f in all_test if "_mask" not in f]

    print("Train Images:", len(train_imgs))
    print("Train Masks :", len(train_masks))
    print("Test Images :", len(test_imgs))

    if len(train_imgs) == 0:
        raise ValueError("Dataset path incorrect!")

    tr_imgs, val_imgs, tr_masks, val_masks = train_test_split(
        train_imgs, train_masks, test_size=0.2, random_state=42
    )

    train_ds = UltrasoundDataset(tr_imgs, tr_masks)
    val_ds   = UltrasoundDataset(val_imgs, val_masks)

    train_loader = DataLoader(train_ds, batch_size=CFG.BATCH, shuffle=True)
    val_loader   = DataLoader(val_ds, batch_size=CFG.BATCH, shuffle=False)

    return train_loader, val_loader, test_imgs

# ------------------------
# Edge-Aware Fusion
# ------------------------
class EdgeAwareFusion(nn.Module):
    def __init__(self):
        super().__init__()
        self.sobel_x = nn.Conv2d(1,1,3,padding=1,bias=False)
        self.sobel_y = nn.Conv2d(1,1,3,padding=1,bias=False)
        self.fuse    = nn.Conv2d(3,1,1)

        sx = torch.tensor([[[-1,0,1],[-2,0,2],[-1,0,1]]],dtype=torch.float32).unsqueeze(0)
        sy = torch.tensor([[[-1,-2,-1],[0,0,0],[1,2,1]]],dtype=torch.float32).unsqueeze(0)
        self.sobel_x.weight.data = sx
        self.sobel_y.weight.data = sy

        for p in self.sobel_x.parameters(): p.requires_grad=False
        for p in self.sobel_y.parameters(): p.requires_grad=False

    def forward(self,x):
        ex = self.sobel_x(x)
        ey = self.sobel_y(x)
        edge = torch.sqrt(ex**2 + ey**2 + 1e-6)
        fused = torch.cat([x, edge, x-edge], dim=1)
        return fused   # 3-channel fused feature map

# ------------------------
# Model Blocks
# ------------------------
class ConvBlock(nn.Module):
    def __init__(self,in_c,out_c):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_c,out_c,3,padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_c,out_c,3,padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True)
        )
    def forward(self,x): return self.conv(x)

class UNetSmall(nn.Module):
    def __init__(self):
        super().__init__()
        self.d1 = ConvBlock(3,32)
        self.d2 = ConvBlock(32,64)
        self.b  = ConvBlock(64,128)
        self.u2 = ConvBlock(128+64,64)
        self.u1 = ConvBlock(64+32,32)
        self.out = nn.Conv2d(32,1,1)

    def forward(self,x):
        c1 = self.d1(x); p1 = F.max_pool2d(c1,2)
        c2 = self.d2(p1); p2 = F.max_pool2d(c2,2)
        b  = self.b(p2)
        u2 = F.interpolate(b,scale_factor=2,mode="bilinear",align_corners=False)
        u2 = self.u2(torch.cat([u2,c2],1))
        u1 = F.interpolate(u2,scale_factor=2,mode="bilinear",align_corners=False)
        u1 = self.u1(torch.cat([u1,c1],1))
        return self.out(u1)

class SegNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.enc = nn.Sequential(
            nn.Conv2d(3,64,3,padding=1),nn.ReLU(),nn.MaxPool2d(2),
            nn.Conv2d(64,128,3,padding=1),nn.ReLU(),nn.MaxPool2d(2))
        self.dec = nn.Sequential(
            nn.Upsample(scale_factor=2),
            nn.Conv2d(128,64,3,padding=1),nn.ReLU(),
            nn.Upsample(scale_factor=2),
            nn.Conv2d(64,1,3,padding=1))
    def forward(self,x): return self.dec(self.enc(x))

class AttentionUNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.c1 = ConvBlock(3,32)
        self.c2 = ConvBlock(32,64)
        self.b  = ConvBlock(64,128)
        self.att = nn.Sequential(nn.Conv2d(128,64,1),nn.Sigmoid())
        self.u2 = ConvBlock(128+64,64)
        self.u1 = ConvBlock(64+32,32)
        self.out = nn.Conv2d(32,1,1)

    def forward(self,x):
        c1 = self.c1(x); p1 = F.max_pool2d(c1,2)
        c2 = self.c2(p1); p2 = F.max_pool2d(c2,2)
        b  = self.b(p2)
        up2 = F.interpolate(b,scale_factor=2,mode="bilinear",align_corners=False)
        att = self.att(up2)
        u2 = self.u2(torch.cat([up2,c2*att],1))
        u1 = F.interpolate(u2,scale_factor=2,mode="bilinear",align_corners=False)
        u1 = self.u1(torch.cat([u1,c1],1))
        return self.out(u1)

# ------------------------
# Metrics
# ------------------------
def dice_score(pred,mask):
    pred = torch.sigmoid(pred)
    pred = (pred>0.5).float()
    inter = (pred*mask).sum()
    union = pred.sum()+mask.sum()
    return (2*inter+1e-6)/(union+1e-6)

# ------------------------
# Training with History
# ------------------------
def train_model(model,fusion,train_loader,val_loader,model_name):
    model.to(CFG.device)
    fusion.to(CFG.device)

    opt = torch.optim.Adam(list(model.parameters())+list(fusion.parameters()),lr=CFG.LR)
    criterion = nn.BCEWithLogitsLoss()

    train_loss_hist=[]
    val_dice_hist=[]
    time_hist=[]

    for epoch in range(CFG.EPOCHS):
        start=time.time()
        model.train(); fusion.train()
        total_loss=0

        for imgs,masks in train_loader:
            imgs,masks = imgs.to(CFG.device), masks.to(CFG.device)

            fused = fusion(imgs)
            preds = model(fused)
            loss = criterion(preds,masks)

            opt.zero_grad()
            loss.backward()
            opt.step()
            total_loss+=loss.item()

        avg_loss = total_loss/len(train_loader)
        train_loss_hist.append(avg_loss)

        model.eval(); fusion.eval()
        vd=0
        with torch.no_grad():
            for imgs,masks in val_loader:
                imgs,masks = imgs.to(CFG.device), masks.to(CFG.device)
                preds = model(fusion(imgs))
                vd+=dice_score(preds,masks).item()

        avg_dice = vd/len(val_loader)
        val_dice_hist.append(avg_dice)

        epoch_time=time.time()-start
        time_hist.append(epoch_time)

        print(f"{model_name} | Epoch {epoch+1}/{CFG.EPOCHS} | Loss {avg_loss:.4f} | Dice {avg_dice:.4f} | Time {epoch_time:.1f}s")

    return train_loss_hist,val_dice_hist,time_hist

# ------------------------
# Plotting Curves
# ------------------------
def plot_curves(train_loss,val_dice,time_hist,model_name):

    plt.figure()
    plt.plot(train_loss,marker='o')
    plt.title(f"{model_name} - Training Loss")
    plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.grid()
    plt.show()

    plt.figure()
    plt.plot(val_dice,marker='o')
    plt.title(f"{model_name} - Validation Dice")
    plt.xlabel("Epoch"); plt.ylabel("Dice"); plt.grid()
    plt.show()

    plt.figure()
    plt.plot(time_hist,val_dice,marker='o')
    plt.title(f"{model_name} - Time vs Dice")
    plt.xlabel("Time per Epoch (s)")
    plt.ylabel("Validation Dice")
    plt.grid()
    plt.show()

# ------------------------
# Run Training
# ------------------------
train_loader,val_loader,test_imgs = build_loaders()

models={
    "UNetSmall":UNetSmall(),
    "SegNet":SegNet(),
    "AttentionUNet":AttentionUNet()
}

for name,model in models.items():
    print("\nTraining:",name)
    fusion = EdgeAwareFusion()
    tr_loss,val_dice,t_hist = train_model(model,fusion,train_loader,val_loader,name)
    plot_curves(tr_loss,val_dice,t_hist,name)
